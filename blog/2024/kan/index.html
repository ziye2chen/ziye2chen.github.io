<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Introduction to KAN | Ziye Chen </title> <meta name="author" content="Ziye Chen"> <meta name="description" content="this is an introduction about KAN"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ziye2chen.github.io/blog/2024/kan/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Introduction to KAN",
            "description": "this is an introduction about KAN",
            "published": "June 01, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziye</span> Chen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Introduction to KAN</h1> <p>this is an introduction about KAN</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#kan-and-mlp">KAN and MLP</a> </div> <div> <a href="#the-drawbacks-of-mlp">The drawbacks of MLP</a> </div> <div> <a href="#kolmogorov-arnold-networks">Kolmogorov-Arnold Networks</a> </div> <ul> <li> <a href="#the-kolmogorov-arnold-representation-theorem">The Kolmogorov-Arnold representation theorem</a> </li> <li> <a href="#why-kan-is-awesome">Why KAN is awesome</a> </li> <li> <a href="#the-details-about-kans">The details about KANs</a> </li> </ul> </nav> </d-contents> <h2 id="kan-and-mlp">KAN and MLP</h2> <p>change!!!!!</p> <p>The emergence of the <a href="https://arxiv.org/pdf/2404.19756" rel="external nofollow noopener" target="_blank">KANs (Kolmogorov-Arnold Networks)</a> model has led to heated discussions in the AI community, and the reason for this is that the flaws in the structure of the MLPs itself have been troubling the researchers involved.</p> <p>Nowadays, most AI research is based on MLP. The appearance of KANs can potentially revolutionize the direction of AI research. If KANs are as marvelous as expected in subsequent research, their appearance will be like the emergence of cement in a society that has been only using wood to build houses.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/2_1-480.webp 480w,/assets/img/KAN/2_1-800.webp 800w,/assets/img/KAN/2_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/2_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="the-drawbacks-of-mlp">The drawbacks of MLP</h2> <p>The theoretical basis for MLPs is that a single hidden layer network containing enough neurons can approximate any continuous function. But MLPs have some natural flaws:</p> <h3 id="vanishing-and-exploding-gradients">Vanishing and exploding gradients</h3> <p><strong><em>Vanishing gradients:</em></strong> the gradient tends to zero, the network weights cannot be updated or are updated very slightly, and the network will not be effective even if it is trained for a long time;</p> <p><strong><em>Exploding gradient:</em></strong> the gradient grows exponentially and becomes very large, leading to a large update of the network weights, making the network unstable.</p> <p>Whether the gradient disappears or the gradient explosion is essentially due to the backpropagation of the deep neural network.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/NN-480.webp 480w,/assets/img/KAN/NN-800.webp 800w,/assets/img/KAN/NN-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/NN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>For example, in a four-layer neural network, its backpropagation formula is as follows:</p> \[\frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial y_4} \frac{\partial y_4}{\partial z_4} \frac{\partial z_4}{\partial y_3} \frac{\partial y_3}{\partial z_3} \frac{\partial z_3}{\partial y_2} \frac{\partial y_2}{\partial z_2} \frac{\partial z_2}{\partial y_1} \frac{\partial y_1}{\partial z_1} \frac{\partial z_1}{\partial w_1}\] \[\frac{\partial L}{\partial y_4} = \sigma'(z_4) w_4 \sigma'(z_3) w_3 \sigma'(z_2) w_2 \sigma'(z_1) x_1\] <p>where \(y_i = \sigma(z_i) = \sigma(w_i x_i + b_i)\), which \(x_i = y_{i-1}\), and \(\sigma\) is <strong><em>sigmoid</em></strong> activation function.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/sigmoid-480.webp 480w,/assets/img/KAN/sigmoid-800.webp 800w,/assets/img/KAN/sigmoid-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/sigmoid.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>From the above, it can be seen that there is a sequence of multiplications in the backpropagation of the neural network. Also, the derivative of the sigmoid activation function has a value range of 0 to 0.25. So when each \(w_i\) is small, and there are many \(\sigma'\) multiplied together, the gradient tends to 0. When each \(w_i\) very large, the gradient becomes very large.</p> <p>While many methods say they solve this problem, the issue is still complicated to avoid completely, as it is an intrinsic shortcoming of MLPs.</p> <h3 id="inefficient-utilization-of-parameters">Inefficient utilization of parameters</h3> <p>MLPs usually use fully connected networks, so the number of parameters is huge. When the network becomes very deep, only a few parameters are utilized. And this is one reason why LLM may have reached a dead end.</p> <p>Although it is possible to simplify the structure using CNNs or regularization or the like, essentially, the structure of a highly dense continuous linear model coupled with an activation function dictates that the MLP can’t be too sparse or will not have enough representational power.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/cnn-480.webp 480w,/assets/img/KAN/cnn-800.webp 800w,/assets/img/KAN/cnn-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/cnn.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="inadequate-capacity-to-handle-high-dimensional-data-and-long-term-dependency-issues">Inadequate capacity to handle high-dimensional data and Long-term dependency issues</h3> <p>MLPs do not utilize the intrinsic structure of the data, such as local spatial correlations in images and sequence information in textual data. Although CNN and RNN can improve these problems, this base module of MLPs determines that these problems cannot be solved completely.</p> <p>MLPs also have difficulty capturing long-standing relationships in input sequences. (RNN &amp; Transformer can improve it)</p> <h2 id="kolmogorov-arnold-networks">Kolmogorov-Arnold Networks</h2> <h3 id="the-kolmogorov-arnold-representation-theorem">The Kolmogorov-Arnold representation theorem</h3> <p>KANs are inspired by the Kolmogorov-Arnold representation theorem. Vladimir Arnold and Andrey Kolmogorov established that if f is a multivariate continuous function on a bounded domain, then f can be written as a finite composition of continuous functions of a single variable and the binary operation of addition.</p> <p>More specifically, for a smooth \(f : [0, 1]^n \rightarrow \mathbb{R}\),</p> \[f(\mathbf{x}) = f(x_1, \dots, x_n) = \sum_{q=1}^{2n+1} \Phi_q \left( \sum_{p=1}^n \phi_{q,p}(x_p) \right)\] <p>where \(\phi_{q,p} : [0,1] \rightarrow \mathbb{R}\) and \(\Phi_q : \mathbb{R} \rightarrow \mathbb{R}\). This theorem reveals how any multivariate continuous function can be represented by a simpler set of functions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/2_2-480.webp 480w,/assets/img/KAN/2_2-800.webp 800w,/assets/img/KAN/2_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/2_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>It can be shown that the Kolmogorov-Arnold representation theorem is a simple KANs which has only two-layer nonlinearities and a small number of terms (2n + 1) in the hidden layer. This structure appeared a long time ago, but the difficulty is how to make the KANs deeper. And two-layer networks are too simple to approximate complex functions. (Details of deepening KANs will be mentioned later)</p> <h3 id="why-kans-are-awesome">Why KANs are awesome</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/0_1-480.webp 480w,/assets/img/KAN/0_1-800.webp 800w,/assets/img/KAN/0_1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/0_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>KANs contrast MLPs by not having a nested relationship between activation functions and parameter matrices but rather a nesting of directly nonlinear functions \(\Phi\). And \(\Phi\) all use the same function structure. (In the paper, they use the spline function in numerical analysis)</p> \[KAN(x) = (\Phi_{L-1} \circ \Phi_{L-2} \circ \cdots \circ \Phi_1 \circ \Phi_0)x\] \[MLP(x) = (W_{L-1} \circ \sigma \circ W_{L-2} \circ \sigma \circ \cdots \circ W_1 \circ \sigma \circ W_0)x\] <p>When learning the network parameters, MLPs learn the linear function with a fixed nonlinear activation function. In contrast, KANs learn the parameterized nonlinear function directly, which enhances their characterization ability.</p> <p>Because of the parameters’ complexity, although individual spline functions are more complex to learn than linear functions, KANs typically allow for smaller computational graphs than MLPs (i.e., a smaller network size is required to achieve the same effect).</p> <h3 id="the-details-about-kans">The details about KANs</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/spline-480.webp 480w,/assets/img/KAN/spline-800.webp 800w,/assets/img/KAN/spline-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/spline.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>If MLPs fit a function with some lines, KANs fit a function with some curves. In KANs, the spline function is used as the nonlinear function \(\Phi\).</p> <p>The KAN layer is simply a matrix of functions \(\Phi = \{ \phi_{q,p} \}\), \(p=1,2,\cdots,n_{\text{in}}\), $$q=1,2,\cdots,n_{\text{out}}.</p> \[\Phi_l = \left( \begin{array}{ccc} \phi_{l,1,1}(\cdot) &amp; \phi_{l,1,2}(\cdot) &amp; \cdots &amp; \phi_{l,1,n_l}(\cdot) \\ \phi_{l,2,1}(\cdot) &amp; \phi_{l,2,2}(\cdot) &amp; \cdots &amp; \phi_{l,2,n_l}(\cdot) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \phi_{l,n_{l+1},1}(\cdot) &amp; \phi_{l,n_{l+1},2}(\cdot) &amp; \cdots &amp; \phi_{l,n_{l+1},n_l}(\cdot) \end{array} \right)\] \[X_{l+1} = \Phi_l X_l\] <p>where \(\Phi_l\) is the function matrix corresponding to the \(l_{\text{th}}\) KAN layer.</p> <p>Although the KAN layer looks very simple, it is not easy to make it well optimizable. The key tricks are as follows:</p> <h4 id="1-residual-activation-functions">1. Residual activation functions：</h4> \[\phi(x) = w \big(b(x) + \text{spline}(x)\big)\] <p>\(b(x)\) is a basis function,</p> \[b(x) = \text{SiLU}(x) = \frac{x}{1 + e^{-x}}\] <p>SiLU (Sigmoid Linear Unit) function is an improved version of Sigmoid and ReLU.SiLU has the properties of having no upper and lower bounds, and it is smooth and non-monotonic.SiLU works better than ReLU on deep models. It can be seen as a smooth ReLU activation function.SiLU activation function is also known as the Swish activation function, an adaptive activation function introduced by Google Brain in 2017.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/SiLU-480.webp 480w,/assets/img/KAN/SiLU-800.webp 800w,/assets/img/KAN/SiLU-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/SiLU.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>\(\text{spline}(x)\) is parametrized as a linear combination of B-splines such that</p> \[\text{spline}(x) = \sum_i c_i B_i(x)\] <p>where every \(c_i\) is trainable. The B-spline function \(\text{spline}(x)\) can be considered a linear combination of control points \(c_i\) and a weighting function \(B_i(x)\). In short, the B-spline curve is the weighted sum of each control point multiplied by its corresponding weight function. The weighting function is predefined and is only related to order D, and it does not change as the control points change.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/KAN/bSpline-480.webp 480w,/assets/img/KAN/bSpline-800.webp 800w,/assets/img/KAN/bSpline-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/KAN/bSpline.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>In principle \(w\) is redundant since it can be absorbed into \(b(x)\) and \(\text{spline}(x)\). However \(w\) can better control the overall magnitude of the activation function.</p> <h4 id="2-initialization-scales">2. Initialization scales:</h4> <p>Each activation function is initialized to have \(\text{spline}(x) \approx 0\).</p> <p>\(w\) is initialized according to Xavier initialization. Xavier initialization is a very effective method for initializing neural networks, and the method originates from a 2010 paper, <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="external nofollow noopener" target="_blank">Understanding the difficulty of training deep feedforward neural networks</a>.</p> <p>In the paper, Xavier Glorot offers the insight that the variance of the activation values decreases layer by layer, which results in the gradient in backpropagation and also decreases layer by layer. The solution to the vanishing gradient is to avoid the decay of the variance of the activation values and, ideally, to keep the output values (activation values) of each layer Gaussian distributed. So they initialized the weights \(W\) at each layer with the following commonly used heuristic:</p> \[W \sim U\left[-\frac{\sqrt{6}}{\sqrt{n_j + n_{j+1}}}, \frac{\sqrt{6}}{\sqrt{n_j + n_{j+1}}}\right]\] <p>where \(n_j\) is the number of inputs, and \(n_{j+1}\) is the number of outputs.</p> <p>In addition, each KAN layer has an equal layer width, with L layers and N nodes per layer.</p> <p>Each spline function is typically of order k = 3, G intervals, and G + 1 grid points.</p> <p>Thus KANs require a total of \(O(N^2L(G+k))\) or \(O(N^2LG)\) parameters, while MLPs require \(O(N^2L)\) parameters. It may seem that the computational complexity of KANs is greater than that of MLPs, but KANs require much less \(N\) than MLPs, which not only saves parameters but also improves generalization and aids interpretability.</p> <h4 id="3-update-of-spline-grids">3. Update of spline grids:</h4> <p>In KANs, they update each grid on the fly according to its input activations, to address the issue that splines are defined on bounded regions but activation values can evolve out of the fixed region during training.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Ziye Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-people",title:"people",description:"members of the lab or group",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-introduction-to-kan",title:"Introduction to KAN",description:"this is an introduction about KAN",section:"Posts",handler:()=>{window.location.href="/blog/2024/kan/"}},{id:"post-the-detail-about-attention-structure",title:"The detail about Attention structure",description:"this is the detail about attention structure",section:"Posts",handler:()=>{window.location.href="/blog/2024/attention/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-modern-solution-of-optimal-transport-sinkhorn",title:"Modern Solution of Optimal Transport - Sinkhorn",description:"this is my study note about sinkhorn",section:"Posts",handler:()=>{window.location.href="/blog/2024/sinkhorn/"}},{id:"post-optimal-transport",title:"Optimal Transport",description:"this is an introduction about Optimal Transport",section:"Posts",handler:()=>{window.location.href="/blog/2024/optimal-transport/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%69%79%65%63%68%65%6E@%62%75.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>