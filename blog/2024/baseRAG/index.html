<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Knolwedge of RAG | Ziye Chen </title> <meta name="author" content="Ziye Chen"> <meta name="description" content="This is a my study note of base RAG. And the required knowledge like Transformer, BERT, BART and DPR are also mentioned."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ziye2chen.github.io/blog/2024/baseRAG/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "The Knolwedge of RAG",
            "description": "This is a my study note of base RAG. And the required knowledge like Transformer, BERT, BART and DPR are also mentioned.",
            "published": "October 08, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziye</span> Chen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>The Knolwedge of RAG</h1> <p>This is a my study note of base RAG. And the required knowledge like Transformer, BERT, BART and DPR are also mentioned.</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#two-components-of-rag">Two Components of RAG</a> </div> <div> <a href="#two-different-models">Two Different Models</a> </div> <div> <a href="#transformer-bert-and-bart">Transformer, BERT, and BART</a> </div> <div> <a href="#dpr">DPR</a> </div> <div> <a href="#retriever">Retriever</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Pre-trained language models’ ability to access and <strong>precisely manipulate knowledge</strong> is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems.</p> <p>RAG combines pre-trained parametric and non-parametric memory for language generation, where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/rag-480.webp 480w,/assets/img/baseRAG/rag-800.webp 800w,/assets/img/baseRAG/rag-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/rag.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>They build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. They combine these components in a probabilistic model trained end-to-end</p> <p>The retriever (Dense Passage Retriever, henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART) then conditions on these latent documents together with the input to generate the output.</p> <h2 id="two-components-of-rag">Two Components of RAG</h2> <p>RAG models leverage two components:</p> <ol> <li>Retriever:</li> </ol> <table> <tbody> <tr> <td>A retriever $$ p_{\eta}(z</td> <td>x) \(with parameters\) \eta \(that returns (top-K truncated) distribution over text passages given the input\) x $$</td> </tr> </tbody> </table> <ol> <li>Generator:</li> </ol> <table> <tbody> <tr> <td>A generator $$ p_{\theta}(y_i</td> <td>x,z,y_{1:i-1}) \(parameterized by\) \theta \(that generates a current token based on a context of previous\) i - 1 \(, the original input\) x \(, and the retrieved text passages\) z $$</td> </tr> </tbody> </table> <h2 id="two-different-models">Two Different Models</h2> <p>There are two different RAG models that marginalize over the latent documents in different ways. To remind you what is marginalization, let’s consider the following example:</p> <table> <tbody> <tr> <td>Suppose you’re interested in how a person’s exercise habits influence their health. You can write this as $$ P(\text{health}</td> <td>\text{exercise}) \(. However, people’s health is also affected by their age, so you actually measure\) P(\text{health}, \text{age}</td> <td>\text{exercise}) $$ —the joint probability of health and age given exercise habits. To focus on just the impact of exercise on health, marginalization allows you to sum over all possible ages:</td> </tr> </tbody> </table> \[P(\text{health} | \text{exercise}) = \sum_{age} P(\text{health}, \text{age} | \text{exercise})\] <p>Let’s come back to RAG models. The difference between the two models is in how they marginalize over the latent documents:</p> <ul> <li> <ol> <li>RAG-sequence: The RAG-Sequence model uses the same retrieved documents to generatethe complete sequence. This model generates an entire answer based on a single document retrieved from the top-K documents. It uses marginalization over the top K documents at the end, treating the retrieved document as a single latent variable to generate the full sequence of the answer.</li> </ol> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/ragSeq-480.webp 480w,/assets/img/baseRAG/ragSeq-800.webp 800w,/assets/img/baseRAG/ragSeq-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/ragSeq.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <ol> <li>RAG-token: The RAG-Token model draws a different latent document for each target token and marginalizes accordingly. This model generates each token of the answer by selecting a different document from the top K retrieved documents for every token. It marginalizes at each token generation step, allowing content from multiple documents to be incorporated into the answer, creating a more diverse and flexible output.</li> </ol> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/ragToken-480.webp 480w,/assets/img/baseRAG/ragToken-800.webp 800w,/assets/img/baseRAG/ragToken-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/ragToken.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><em>**Imagine you ask a question and want to get a answer from an intelligent assistant. The intelligent assistant will find several relevant books from a library and then generate the entire answer based on the contents of those books. During this process, it will keep referring to the same book until the end of the answer. After that, it will compare the answers and select the best one. The RAG-Sequence model is like this helper, it always relies on the same book (one document) when generating the answer, and then compares the answers generated from multiple documents to give the final answer. But the intelligent assistant of RAG-Token is different. Instead of using only one book, the intelligent assistant picks a word from a different book each time it wants to generate a word to combine the answer. For example, it might use the first book to generate the first word, and then the second book to generate the next word. Finally, it combines the words it picks from different books each time to get a complete answer. The RAG-Token model can refer to different books (documents) when generating each word, so each word can potentially originate from a different place. **</em></p> <h2 id="transformer-bert-and-bart">Transformer, BERT, and BART</h2> <p>Transformer is a type of neural network architecture that is particularly well-suited for natural language processing tasks. It uses attention mechanisms to capture the relationships between words in a sentence and uses a self-attention mechanism to encode the entire sentence into a fixed-size vector representation. BERT and BART are both transformer-based models that are pre-trained on large corpora of text and fine-tuned on a specific task. BERT is a bidirectional transformer that can be fine-tuned for a variety of tasks, including question answering, text classification, and token classification. BART is a sequence-to-sequence transformer that is specifically designed for text-to-text generation tasks, such as summarization, translation, and question answering.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/transformer-480.webp 480w,/assets/img/baseRAG/transformer-800.webp 800w,/assets/img/baseRAG/transformer-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/transformer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Transformer consists of two parts: the encoder and the decoder. The encoder processes the input sequence and produces a fixed-size representation of the entire sequence. The decoder processes the encoded representation and produces the output sequence. The attention mechanism allows the decoder to focus on different parts of the input sequence based on the encoded representation.</p> <hr> <p>BERT’s model architecture is a multi-layer bidirectional Transformer encoder</p> <p>In the base BERT model, there are 12 layers of encoder (\(L=12\)), 12 Attention in each layer (\(A=12\)), and the hidden size, which is also the dimension of the word vector, is 768 (\(H=768\)). The total parameters of base BERT is 110 million. In the large BERT model, there are 24 layers of encoder (\(L=24\)), 16 Attention in each layer (\(A=16\)), and the dimension of the word vector is 1024 (\(H=1024\)). The total parameters of large BERT is 340 million. And in all cases, the feed-forward/filter size is 4 times the hidden size.</p> <p>The input will firstly be passed through the embedding layer, which is a learned representation of each word in the vocabulary. The embedding layer in BERT consists of Token Embedding, Positional Embedding, and Segment Embedding.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/embeddingBERT-480.webp 480w,/assets/img/baseRAG/embeddingBERT-800.webp 800w,/assets/img/baseRAG/embeddingBERT-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/embeddingBERT.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Then it will be passed through the encoder layers, the number of layers is 12 in the base model and 24 in the large model. Each layer applies a multi-head attention layer, and passes its results through a fully connected feed-forward network, and then hands it off to the next encoder.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/middleBERT-480.webp 480w,/assets/img/baseRAG/middleBERT-800.webp 800w,/assets/img/baseRAG/middleBERT-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/middleBERT.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>And we can get the output sequence from the final encoder layer. In different tasks, the output sequence will be processed differently.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/baseRAG/outputBERT-480.webp 480w,/assets/img/baseRAG/outputBERT-800.webp 800w,/assets/img/baseRAG/outputBERT-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/baseRAG/outputBERT.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>Link to the paper of BERT: <a href="https://arxiv.org/abs/1810.04805" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/1810.04805</a> </li> </ul> <h2 id="dpr">DPR</h2> <p>Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&amp;A research. Given a collection of \(M\) text passages, the goal of DPR is to index all the passages in a low-dimensional and continuous space, such that it can retrieve efficiently the top-k passages relevant to the input question for the reader at run-time. Note that \(M\) can be very large and \(k\) is usually small, such as 20 to 100.</p> <ul> <li>Link to paper: <a href="https://arxiv.org/abs/2004.04906" rel="external nofollow noopener" target="_blank">https://arxiv.org/abs/2004.04906</a> </li> <li>Link to Github: <a href="https://github.com/facebookresearch/DPR" rel="external nofollow noopener" target="_blank">https://github.com/facebookresearch/DPR</a> </li> </ul> <h2 id="retriever">Retriever</h2> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ziye Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-the-knolwedge-of-rag",title:"The Knolwedge of RAG",description:"This is a my study note of base RAG. And the required knowledge like Transformer, BERT, BART and DPR are also mentioned.",section:"Posts",handler:()=>{window.location.href="/blog/2024/baseRAG/"}},{id:"post-neuronal-wiring-diagram-of-an-adult-brain",title:"Neuronal Wiring Diagram of An Adult Brain",description:"This is my presentation about the Nature paper &quot;Neuronal Wiring Diagram of An Adult Brain&quot;. Since I am not a researcher in the field of neuroscience, here is my simple summary of this paper.",section:"Posts",handler:()=>{window.location.href="/blog/2024/Neuro/"}},{id:"post-encoder",title:"Encoder",description:"this is a blog about the encoder in transformer",section:"Posts",handler:()=>{window.location.href="/blog/2024/Encoder/"}},{id:"post-introduction-to-kan",title:"Introduction to KAN",description:"this is an introduction about KAN",section:"Posts",handler:()=>{window.location.href="/blog/2024/kan/"}},{id:"post-the-detail-about-attention-structure",title:"The detail about Attention structure",description:"this is the detail about attention structure",section:"Posts",handler:()=>{window.location.href="/blog/2024/attention/"}},{id:"post-modern-solution-of-optimal-transport-sinkhorn",title:"Modern Solution of Optimal Transport - Sinkhorn",description:"this is my study note about sinkhorn",section:"Posts",handler:()=>{window.location.href="/blog/2024/sinkhorn/"}},{id:"post-optimal-transport",title:"Optimal Transport",description:"this is an introduction about Optimal Transport",section:"Posts",handler:()=>{window.location.href="/blog/2024/optimal-transport/"}},{id:"news-i-39-m-starting-my-m-s-in-artificial-intelligence-at-boston-university",title:"I&#39;m starting my M.S. in Artificial Intelligence at Boston University.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%69%79%65%63%68%65%6E@%62%75.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>